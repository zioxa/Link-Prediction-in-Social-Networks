{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_csv(report, methodName):\n",
    "    lines = report.split('\\n')\n",
    "    line1 = lines[2]\n",
    "    line2 = lines[3]\n",
    "    line3 = lines[5]\n",
    "    line4 = lines[6]\n",
    "    line5 = lines[7]\n",
    "    \n",
    "    row = {}\n",
    "    \n",
    "    row_data1 = ' '.join(line1.split())   \n",
    "    row_data1 = row_data1.split(' ')\n",
    "    row_data2 = ' '.join(line2.split())   \n",
    "    row_data2 = row_data2.split(' ')\n",
    "    row_data3 = ' '.join(line3.split())   \n",
    "    row_data3 = row_data3.split(' ')\n",
    "    row_data4 = ' '.join(line4.split())   \n",
    "    row_data4 = row_data4.split(' ')\n",
    "    row_data5 = ' '.join(line5.split())   \n",
    "    row_data5 = row_data5.split(' ')\n",
    "    \n",
    "    row['Method'] = methodName\n",
    "    row['Test Size'] = sizeOfTest\n",
    "    row[f'precision class {row_data1[0]}'] = float(row_data1[1])    \n",
    "    row[f'precision class {row_data2[0]}'] = float(row_data2[1])\n",
    "    row[f'recall class {row_data1[0]}'] = float(row_data1[2])\n",
    "    row[f'recall class {row_data2[0]}'] = float(row_data2[2])\n",
    "    row[f'f1_score class {row_data1[0]}'] = float(row_data1[3])\n",
    "    row[f'f1_score class {row_data2[0]}'] = float(row_data2[3])\n",
    "    row[f'support class {row_data1[0]}'] = float(row_data1[4])\n",
    "    row[f'support class {row_data2[0]}'] = float(row_data2[4])\n",
    "    row['Accuracy f1-score'] = float(row_data3[1])\n",
    "    row['Accuracy support'] = float(row_data3[2])\n",
    "    row['macro avg precision'] = float(row_data4[2])\n",
    "    row['macro avg recall'] = float(row_data4[3])\n",
    "    row['macro avg f1score'] = float(row_data4[4])\n",
    "    row['macro avg support'] = float(row_data4[5])\n",
    "    row['weighted avg precision'] = float(row_data5[2])\n",
    "    row['weighted avg recall'] = float(row_data5[3])\n",
    "    row['weighted avg f1score'] = float(row_data5[4])\n",
    "    row['weighted avg support'] = float(row_data5[5])\n",
    "    \n",
    "    report_data.append(row) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Class</th>\n",
       "      <th>Page_Rank_Src</th>\n",
       "      <th>Page_Rank_Dst</th>\n",
       "      <th>Shortest_Path</th>\n",
       "      <th>Followers_Src</th>\n",
       "      <th>Followees_Src</th>\n",
       "      <th>Followers_Dst</th>\n",
       "      <th>Followees_Dst</th>\n",
       "      <th>...</th>\n",
       "      <th>In_degree_Cen_Src</th>\n",
       "      <th>Out_degree_Cen_Src</th>\n",
       "      <th>In_degree_Cen_Dst</th>\n",
       "      <th>Out_degree_Cen_Dst</th>\n",
       "      <th>Eigenvec_Cen_Src</th>\n",
       "      <th>Eigenvec_Cen_Dst</th>\n",
       "      <th>Core_Num_Src</th>\n",
       "      <th>Core_Num_Dst</th>\n",
       "      <th>LCC_Source</th>\n",
       "      <th>LCC_Destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6194</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6194</td>\n",
       "      <td>980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6194</td>\n",
       "      <td>2992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>5.715021e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6194</td>\n",
       "      <td>2507</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>1.470102e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6194</td>\n",
       "      <td>986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>3.257143e-19</td>\n",
       "      <td>7.491428e-18</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Destination  Class  Page_Rank_Src  Page_Rank_Dst  Shortest_Path  \\\n",
       "0    6194          255      1       0.000016       0.000013             -1   \n",
       "1    6194          980      1       0.000016       0.000015             -1   \n",
       "2    6194         2992      1       0.000016       0.000016              4   \n",
       "3    6194         2507      1       0.000016       0.000057              3   \n",
       "4    6194          986      1       0.000016       0.000023              9   \n",
       "\n",
       "   Followers_Src  Followees_Src  Followers_Dst  Followees_Dst  ...  \\\n",
       "0              0              4              0              5  ...   \n",
       "1              0              4              0             15  ...   \n",
       "2              0              4              3              0  ...   \n",
       "3              0              4              8             14  ...   \n",
       "4              0              4              1             21  ...   \n",
       "\n",
       "   In_degree_Cen_Src  Out_degree_Cen_Src  In_degree_Cen_Dst  \\\n",
       "0                0.0            0.000101           0.000000   \n",
       "1                0.0            0.000101           0.000000   \n",
       "2                0.0            0.000101           0.000076   \n",
       "3                0.0            0.000101           0.000202   \n",
       "4                0.0            0.000101           0.000025   \n",
       "\n",
       "   Out_degree_Cen_Dst  Eigenvec_Cen_Src  Eigenvec_Cen_Dst  Core_Num_Src  \\\n",
       "0            0.000126      3.257143e-19      3.257143e-19             3   \n",
       "1            0.000379      3.257143e-19      3.257143e-19             3   \n",
       "2            0.000000      3.257143e-19      5.715021e-05             3   \n",
       "3            0.000354      3.257143e-19      1.470102e-06             3   \n",
       "4            0.000531      3.257143e-19      7.491428e-18             3   \n",
       "\n",
       "   Core_Num_Dst  LCC_Source  LCC_Destination  \n",
       "0             4         0.0         0.400000  \n",
       "1             8         0.0         0.152381  \n",
       "2             3         0.0         0.000000  \n",
       "3            11         0.0         0.051948  \n",
       "4            11         0.0         0.225108  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_dataset.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaled_data = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70648, 22)\n",
      "(70648, 2)\n"
     ]
    }
   ],
   "source": [
    "x_pca = pca.transform(scaled_data)\n",
    "print(scaled_data.shape)\n",
    "print(x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.from_pandas_edgelist(df[['Source','Destination']], source='Source', target='Destination',create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.drop(columns=['Source', 'Destination', 'Class'])\n",
    "df_y = df[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_data = []\n",
    "sizeOfTest = 0.3\n",
    "# x_train, x_test, y_train, y_test  = train_test_split(df_x, df_y, test_size = sizeOfTest, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train model :  0.48  seconds\n",
      "Time taken to train model :  0.49  seconds\n",
      "Time taken to train model :  0.4  seconds\n",
      "Time taken to train model :  0.39  seconds\n",
      "Time taken to train model :  0.43  seconds\n",
      "Time taken to train model :  0.34  seconds\n",
      "Time taken to train model :  0.38  seconds\n",
      "Time taken to train model :  0.36  seconds\n",
      "Time taken to train model :  0.35  seconds\n",
      "Time taken to train model :  0.25  seconds\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "for i in range(1,11):\n",
    "    x_train, x_test, y_train, y_test  = train_test_split(df_x, df_y, test_size = sizeOfTest, random_state=10*i)\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression(C=2,solver='liblinear', random_state=0).fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    print('Time taken to train model : ', round(end-start,2) , ' seconds')\n",
    "    report = classification_report(lr.predict(x_test), y_test)\n",
    "    classification_report_csv(report,\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     10937\n",
      "           1       0.95      0.97      0.96     10258\n",
      "\n",
      "    accuracy                           0.96     21195\n",
      "   macro avg       0.96      0.96      0.96     21195\n",
      "weighted avg       0.96      0.96      0.96     21195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lr.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train model :  1.43  seconds\n",
      "Time taken to train model :  1.29  seconds\n",
      "Time taken to train model :  1.49  seconds\n",
      "Time taken to train model :  1.3  seconds\n",
      "Time taken to train model :  1.33  seconds\n",
      "Time taken to train model :  1.28  seconds\n",
      "Time taken to train model :  1.37  seconds\n",
      "Time taken to train model :  1.43  seconds\n",
      "Time taken to train model :  1.39  seconds\n",
      "Time taken to train model :  1.48  seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for i in range(1,11):\n",
    "    x_train, x_test, y_train, y_test  = train_test_split(df_x, df_y, test_size = sizeOfTest, random_state=10*i)\n",
    "    start = time.time()\n",
    "    rf=RandomForestClassifier(n_estimators=50,max_depth=9)\n",
    "\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    rf.fit(x_train,y_train)\n",
    "    end = time.time()\n",
    "    print('Time taken to train model : ', round(end-start,2) , ' seconds')\n",
    "    y_pred=rf.predict(x_test)\n",
    "    report = classification_report(y_pred, y_test)\n",
    "    classification_report_csv(report,\"RFC\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     10901\n",
      "           1       0.96      0.97      0.97     10294\n",
      "\n",
      "    accuracy                           0.97     21195\n",
      "   macro avg       0.97      0.97      0.97     21195\n",
      "weighted avg       0.97      0.97      0.97     21195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=rf.predict(x_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train model :  50.63  seconds\n",
      "Time taken to train model :  55.39  seconds\n",
      "Time taken to train model :  60.77  seconds\n",
      "Time taken to train model :  59.9  seconds\n",
      "Time taken to train model :  52.31  seconds\n",
      "Time taken to train model :  54.96  seconds\n",
      "Time taken to train model :  50.8  seconds\n",
      "Time taken to train model :  53.88  seconds\n",
      "Time taken to train model :  49.04  seconds\n",
      "Time taken to train model :  48.82  seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "for i in range(1,11):\n",
    "    x_train, x_test, y_train, y_test  = train_test_split(df_x, df_y, test_size = sizeOfTest, random_state=10*i)\n",
    "    start = time.time()\n",
    "    #Create a svm Classifier\n",
    "    sv = svm.SVC(kernel='linear') # Linear Kernel\n",
    "    #Train the model using the training sets\n",
    "    sv.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    print('Time taken to train model : ', round(end-start,2) , ' seconds')\n",
    "    y_pred=sv.predict(x_test)\n",
    "    report = classification_report(y_pred, y_test)\n",
    "    classification_report_csv(report,\"SVM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     11033\n",
      "           1       0.94      0.97      0.96     10162\n",
      "\n",
      "    accuracy                           0.96     21195\n",
      "   macro avg       0.96      0.96      0.96     21195\n",
      "weighted avg       0.96      0.96      0.96     21195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=sv.predict(x_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train model :  1.21  seconds\n",
      "Time taken to train model :  1.2  seconds\n",
      "Time taken to train model :  1.22  seconds\n",
      "Time taken to train model :  1.21  seconds\n",
      "Time taken to train model :  1.22  seconds\n",
      "Time taken to train model :  1.22  seconds\n",
      "Time taken to train model :  1.22  seconds\n",
      "Time taken to train model :  1.23  seconds\n",
      "Time taken to train model :  1.25  seconds\n",
      "Time taken to train model :  1.22  seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    x_train, x_test, y_train, y_test  = train_test_split(df_x, df_y, test_size = sizeOfTest, random_state=10*i)\n",
    "    start = time.time()\n",
    "    bst = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1 , colsample_bytree = 0.7 ,objective='binary:logistic')\n",
    "\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    bst.fit(x_train,y_train)\n",
    "    end = time.time()\n",
    "    print('Time taken to train model : ', round(end-start,2) , ' seconds')\n",
    "    y_pred=bst.predict(x_test)\n",
    "    report = classification_report(y_pred, y_test)\n",
    "    classification_report_csv(report,\"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train model :  4.75  seconds\n",
      "Time taken to train model :  4.7  seconds\n",
      "Time taken to train model :  4.68  seconds\n",
      "Time taken to train model :  4.76  seconds\n",
      "Time taken to train model :  4.78  seconds\n",
      "Time taken to train model :  4.71  seconds\n",
      "Time taken to train model :  4.67  seconds\n",
      "Time taken to train model :  4.8  seconds\n",
      "Time taken to train model :  4.66  seconds\n",
      "Time taken to train model :  4.69  seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    x_train, x_test, y_train, y_test  = train_test_split(df_x, df_y, test_size = sizeOfTest, random_state=10*i)\n",
    "    start = time.time()\n",
    "    \n",
    "    ada = AdaBoostClassifier(n_estimators=140,\n",
    "                            learning_rate=1,\n",
    "                            algorithm='SAMME.R',\n",
    "                            random_state=1)\n",
    "    ada.fit(x_train, y_train)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print('Time taken to train model : ', round(end-start,2) , ' seconds')\n",
    "    y_pred=ada.predict(x_test)\n",
    "    report = classification_report(y_pred, y_test)\n",
    "    \n",
    "    classification_report_csv(report,\"ADABoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.from_dict(report_data)\n",
    "dataframe.to_csv('classification_report.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
